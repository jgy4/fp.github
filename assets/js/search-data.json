{
  
    
        "post0": {
            "title": "Dive into Deep Learning",
            "content": "The Task . In this blog post we will be using data from Insect Images to train a deep learning model to classify beetles, cockroaches, and dragonflies. We&#39;ll explain the model, measure performance, and explain how the neural network is classifying images with Shapley Additive Explanations. . from __future__ import print_function import numpy as np import pandas as pd import os, sys from numpy import asarray from PIL import Image from sklearn.neural_network import MLPClassifier from tensorflow.keras import Sequential from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout from tensorflow.keras.optimizers import Adam import tensorflow from tensorflow.keras import backend as K import shap import matplotlib.pyplot as plt from tensorflow.keras.utils import plot_model from scipy import ndimage from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img . . Data Pre-Processing . We begin by loading the images of cockroaches, beetles, and dragonflies in our train folder and test folder. We then combine all of our training images into one place with their proper labels, and all of our testing images into one place with their proper labels. Lastly we transform our images into numpy arrays so that they can be fed into the model. . Here&#39;s an example dragonfly image: . &#39;&#39;&#39; Load training data &#39;&#39;&#39; folder = &quot;insects/train/beetles&quot; beetles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))] folder = &quot;insects/train/cockroach&quot; cockroaches = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))] folder = &quot;insects/train/dragonflies&quot; dragonflies = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))] . . &#39;&#39;&#39; Load testing data &#39;&#39;&#39; folder = &quot;insects/test/beetles&quot; test_beetles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))] folder = &quot;insects/test/cockroach&quot; test_cockroaches = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))] folder = &quot;insects/test/dragonflies&quot; test_dragonflies = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))] . . &#39;&#39;&#39; Create full collection of training images and labels &#39;&#39;&#39; train_files = [] y_train = [] i=0 for _file in beetles: train_files.append(&#39;insects/train/beetles/&#39; + _file) y_train.append(0) for _file in cockroaches: train_files.append(&#39;insects/train/cockroach/&#39; + _file) y_train.append(1) for _file in dragonflies: train_files.append(&#39;insects/train/dragonflies/&#39; + _file) y_train.append(2) . . &#39;&#39;&#39; Create full collection of test images and labels &#39;&#39;&#39; test_files = [] y_test = [] i=0 for _file in test_beetles: test_files.append(&#39;insects/test/beetles/&#39; + _file) y_test.append(0) for _file in test_cockroaches: test_files.append(&#39;insects/test/cockroach/&#39; + _file) y_test.append(1) for _file in test_dragonflies: test_files.append(&#39;insects/test/dragonflies/&#39; + _file) y_test.append(2) . . &#39;&#39;&#39; Turn Training Images to Numpy Arrays &#39;&#39;&#39; # Set Image Dimensions image_width = 480 image_height = 480 ratio = 4 image_width = int(image_width / ratio) image_height = int(image_height / ratio) channels = 3 nb_classes = 1 #Create training dataset of images as numpy arrays dataset = np.ndarray(shape=(len(train_files),image_height,image_width,channels), dtype=np.float32) x_train = [] i = 0 for _file in train_files: img = load_img(_file) img = img.resize((image_width, image_height)) # Convert to Numpy Array x = asarray(img) dataset[i] = x i += 1 . . &#39;&#39;&#39; Turn Testing Images to Numpy Arrays &#39;&#39;&#39; test_dataset = np.ndarray(shape=(len(test_files), image_height,image_width,channels), dtype=np.float32) x_test = [] i = 0 for _file in test_files: img = load_img(_file) img = img.resize((image_width, image_height)) # Convert to Numpy Array x = asarray(img) test_dataset[i] = x i += 1 . . img . Creating The Model . We&#39;re using a Sequential model from the Keras library with the following layers: . A 2D convolution layer with a relu activation function | A MaxPooling layer for 2-Dimensional data that downsamples the input by taking the max value among the pool size window (2,2). | A Dropout layer that randomly sets inputs to zero at the rate 0.25 to prevent overfitting. | A Flatten layer that flattens the input. | A Dense layer that implements the &#39;relu&#39; activation function. | Another Dropout layer that reandomly sets inputs to zero at the rate 0.5 to prevent overfitting. | A final Dense layer to implement the &#39;softmax&#39; activation function. | . &#39;&#39;&#39; Tidy up input dataset &#39;&#39;&#39; dataset = dataset.astype(&#39;float32&#39;) test_dataset = test_dataset.astype(&#39;float32&#39;) dataset /= 255 test_dataset /= 255 &#39;&#39;&#39; Set model values &#39;&#39;&#39; batch_size = 128 epochs = 25 num_classes = 3 y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes) y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes) input_shape = (image_height,image_width,channels) &#39;&#39;&#39; Build Model &#39;&#39;&#39; model = Sequential() model.add(Conv2D(32, kernel_size=(3, 3), activation=&#39;relu&#39;, input_shape=input_shape)) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128, activation=&#39;relu&#39;)) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation=&#39;softmax&#39;)) model.compile(loss=tensorflow.keras.losses.categorical_crossentropy, optimizer=&#39;rmsprop&#39;, metrics=[&#39;accuracy&#39;]) . . &#39;&#39;&#39; Fit Model to Our Data &#39;&#39;&#39; hist = model.fit(dataset, y_train, batch_size=batch_size, epochs=epochs, verbose=1) . Epoch 1/25 8/8 [==============================] - 4s 521ms/step - loss: 18.0087 - accuracy: 0.4308 Epoch 2/25 8/8 [==============================] - 4s 516ms/step - loss: 1.3599 - accuracy: 0.6212 Epoch 3/25 8/8 [==============================] - 4s 545ms/step - loss: 0.7698 - accuracy: 0.6673 Epoch 4/25 8/8 [==============================] - 5s 636ms/step - loss: 0.7131 - accuracy: 0.7134 Epoch 5/25 8/8 [==============================] - 4s 546ms/step - loss: 0.5829 - accuracy: 0.7566 Epoch 6/25 8/8 [==============================] - 4s 538ms/step - loss: 0.5741 - accuracy: 0.7704 Epoch 7/25 8/8 [==============================] - 4s 515ms/step - loss: 0.4956 - accuracy: 0.7949 Epoch 8/25 8/8 [==============================] - 4s 525ms/step - loss: 0.7153 - accuracy: 0.7674 Epoch 9/25 8/8 [==============================] - 4s 507ms/step - loss: 0.3780 - accuracy: 0.8597 Epoch 10/25 8/8 [==============================] - 5s 568ms/step - loss: 0.3362 - accuracy: 0.8763 Epoch 11/25 8/8 [==============================] - 5s 567ms/step - loss: 0.3677 - accuracy: 0.8616 Epoch 12/25 8/8 [==============================] - 5s 655ms/step - loss: 0.3065 - accuracy: 0.8930 Epoch 13/25 8/8 [==============================] - 4s 542ms/step - loss: 0.3606 - accuracy: 0.8744 Epoch 14/25 8/8 [==============================] - 5s 569ms/step - loss: 0.1970 - accuracy: 0.9411 Epoch 15/25 8/8 [==============================] - 4s 528ms/step - loss: 0.1823 - accuracy: 0.9431 Epoch 16/25 8/8 [==============================] - 4s 554ms/step - loss: 0.1651 - accuracy: 0.9509 Epoch 17/25 8/8 [==============================] - 4s 562ms/step - loss: 0.2041 - accuracy: 0.9303 Epoch 18/25 8/8 [==============================] - 4s 532ms/step - loss: 0.1636 - accuracy: 0.9421 Epoch 19/25 8/8 [==============================] - 4s 499ms/step - loss: 0.1197 - accuracy: 0.9657 Epoch 20/25 8/8 [==============================] - 5s 610ms/step - loss: 0.1968 - accuracy: 0.9215 Epoch 21/25 8/8 [==============================] - 5s 608ms/step - loss: 0.0921 - accuracy: 0.9774 Epoch 22/25 8/8 [==============================] - 5s 603ms/step - loss: 0.0769 - accuracy: 0.9745 Epoch 23/25 8/8 [==============================] - 4s 494ms/step - loss: 0.1368 - accuracy: 0.9509 Epoch 24/25 8/8 [==============================] - 4s 513ms/step - loss: 0.0585 - accuracy: 0.9872 Epoch 25/25 8/8 [==============================] - 4s 492ms/step - loss: 0.0877 - accuracy: 0.9686 . Evaluating Our Model . We see that our model performs fairly well, with a test loss of 0.095 and a test accuracy of 0.978. The plots below show the change in loss across epochs, and the improvements in accuracy at each epoch. I found that there were minimal accuracy gains from adding more than 25 epochs. . &#39;&#39;&#39; Evaluate Our Model &#39;&#39;&#39; score = model.evaluate(test_dataset, y_test, verbose=0) print(&#39;Test loss:&#39;, score[0]) print(&#39;Test accuracy:&#39;, score[1]) . Test loss: 0.42263150215148926 Test accuracy: 0.8111110925674438 . fig, axes = plt.subplots(1,2,figsize=(12, 4)) for ax, measure, title in zip(axes, [&#39;loss&#39;, &#39;accuracy&#39;], [&#39;Loss Across Epochs&#39;,&#39;Accuracy Across Epochs&#39;]): ax.plot(hist.history[measure], label=measure) ax.title.set_text(title) ax.set_xlabel(&#39;Epoch&#39;) ax.legend() pass . . Understanding Our Model With Shapley . Below we use Shapley Additive Explanations to understand how our deep learning model is classifying images. The first two images are beetles, the next two images are cockroaches, and the last two images are dragonflies. We use shapley&#39;s deep explainer which works by approximating a certain number of samples from our model - in this case 200 images. Red pixels are increasing the model&#39;s output while blue pixels are decreasing the model&#39;s output. The sum of SHAP values represents the difference between the expected model output and the current model output. . We see our beetle images highlighted with red pixels in the first (beetle) column. Our cockroach images are highlighted with red pixels in the center (cockroach) column - though one of our cockroaches has some red pixels in the dragonfly column. Lastly, our two dragonfly images are highlighted with red pixels in the final (dragonfly) column - though has some red pixels in the cockroach column. . import shap import numpy as np &#39;&#39;&#39; Select a set of background examples to take an expectation over &#39;&#39;&#39; background = dataset[np.random.choice(dataset.shape[0], 200, replace=False)] e = shap.DeepExplainer(model, background) &#39;&#39;&#39; Run the explainer for certain images in our dataset &#39;&#39;&#39; shap_values = e.shap_values(test_dataset[[1,2,65,66,154,158]]) shap.image_plot(shap_values, test_dataset[[1,2,65,66,154,158]]) . . WARNING:tensorflow:From /Users/jasmineyoung/opt/anaconda3/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:239: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11. Instructions for updating: Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model. .",
            "url": "https://jgy4.github.io/fp.github/2021/11/11/Dive-Into-Deep-Learning.html",
            "relUrl": "/2021/11/11/Dive-Into-Deep-Learning.html",
            "date": " • Nov 11, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Is There Life After Graduate School?",
            "content": "The Task . In this blog post we will be using data from Science and Engineering PhDs awarded in the US. We will perform some analysis in pandas and make a dashboard visualization of a few interesting aspects of the data. . Plotly &amp; Dash . I chose to use plotly for my visualizations and Dash to power my dashboard because it was easily integrated into Jupyter notebook. Plotly allows you to easily create interactive visualizations using python. I found Dash to be straightforward and easily customizable when working with Plotly visualizations. . Data Analysis In Pandas . The data transformations and analysis necessary to create the dashboard can be viewed below. . table2 = pd.read_excel(&#39;tab001.xlsx&#39;, index_col=0, header=3) table2 = table2.replace(&#39;-&#39;, 0) table2.reset_index(level=0, inplace=True) . . table4 = pd.read_excel(&#39;tab006.xlsx&#39;, index_col=0, header=[3,4]) . . us_state_to_abbrev = { &quot;Alabama&quot;: &quot;AL&quot;, &quot;Alaska&quot;: &quot;AK&quot;, &quot;Arizona&quot;: &quot;AZ&quot;, &quot;Arkansas&quot;: &quot;AR&quot;, &quot;California&quot;: &quot;CA&quot;, &quot;Colorado&quot;: &quot;CO&quot;, &quot;Connecticut&quot;: &quot;CT&quot;, &quot;Delaware&quot;: &quot;DE&quot;, &quot;Florida&quot;: &quot;FL&quot;, &quot;Georgia&quot;: &quot;GA&quot;, &quot;Hawaii&quot;: &quot;HI&quot;, &quot;Idaho&quot;: &quot;ID&quot;, &quot;Illinois&quot;: &quot;IL&quot;, &quot;Indiana&quot;: &quot;IN&quot;, &quot;Iowa&quot;: &quot;IA&quot;, &quot;Kansas&quot;: &quot;KS&quot;, &quot;Kentucky&quot;: &quot;KY&quot;, &quot;Louisiana&quot;: &quot;LA&quot;, &quot;Maine&quot;: &quot;ME&quot;, &quot;Maryland&quot;: &quot;MD&quot;, &quot;Massachusetts&quot;: &quot;MA&quot;, &quot;Michigan&quot;: &quot;MI&quot;, &quot;Minnesota&quot;: &quot;MN&quot;, &quot;Mississippi&quot;: &quot;MS&quot;, &quot;Missouri&quot;: &quot;MO&quot;, &quot;Montana&quot;: &quot;MT&quot;, &quot;Nebraska&quot;: &quot;NE&quot;, &quot;Nevada&quot;: &quot;NV&quot;, &quot;New Hampshire&quot;: &quot;NH&quot;, &quot;New Jersey&quot;: &quot;NJ&quot;, &quot;New Mexico&quot;: &quot;NM&quot;, &quot;New York&quot;: &quot;NY&quot;, &quot;North Carolina&quot;: &quot;NC&quot;, &quot;North Dakota&quot;: &quot;ND&quot;, &quot;Ohio&quot;: &quot;OH&quot;, &quot;Oklahoma&quot;: &quot;OK&quot;, &quot;Oregon&quot;: &quot;OR&quot;, &quot;Pennsylvania&quot;: &quot;PA&quot;, &quot;Rhode Island&quot;: &quot;RI&quot;, &quot;South Carolina&quot;: &quot;SC&quot;, &quot;South Dakota&quot;: &quot;SD&quot;, &quot;Tennessee&quot;: &quot;TN&quot;, &quot;Texas&quot;: &quot;TX&quot;, &quot;Utah&quot;: &quot;UT&quot;, &quot;Vermont&quot;: &quot;VT&quot;, &quot;Virginia&quot;: &quot;VA&quot;, &quot;Washington&quot;: &quot;WA&quot;, &quot;West Virginia&quot;: &quot;WV&quot;, &quot;Wisconsin&quot;: &quot;WI&quot;, &quot;Wyoming&quot;: &quot;WY&quot;, &quot;District of Columbia&quot;: &quot;DC&quot;, &quot;American Samoa&quot;: &quot;AS&quot;, &quot;Guam&quot;: &quot;GU&quot;, &quot;Northern Mariana Islands&quot;: &quot;MP&quot;, &quot;Puerto Rico&quot;: &quot;PR&quot;, &quot;United States Minor Outlying Islands&quot;: &quot;UM&quot;, &quot;U.S. Virgin Islands&quot;: &quot;VI&quot;, } . . t401 = table4.groupby(level=0, axis=1).sum() t401 = t401.replace(&#39;DD&#39;,0) t401[&#39;abbrev&#39;] = t401.index.map(us_state_to_abbrev) t401 = t401.drop([&#39;United Statesd&#39;]) for col in t401.columns: t401[col] = t401[col].astype(str) t401[&#39;Text&#39;] = &#39; Education: &#39; + t401[&#39;Education&#39;] + &#39; Engineering: &#39; + t401[&#39;Engineering&#39;] + &#39;&lt;br&gt;&#39; + &#39; Humanities &amp; Arts: &#39; + t401[&#39;Humanities and arts&#39;] + &#39; Life Sciences: &#39; + t401[&#39;Life sciencesb&#39;] + &#39;&lt;br&gt;&#39; + &#39; Math &amp; Computer Sciences: &#39; + t401[&#39;Mathematics and computer sciences&#39;] + &#39; Other: &#39; + t401[&#39;Otherc&#39;] + &#39;&lt;br&gt;&#39; + &#39; Physical &amp; Earth Sciences: &#39; + t401[&#39;Physical sciences and earth sciences &#39;] + &#39; Psychology &amp; Social Sciences: &#39; + t401[&#39;Psychology and social sciences&#39;] . . t402 = table4.groupby(level=0, axis=1).sum() t402 = t402.iloc[: , :-1] t402 = pd.DataFrame(t402.loc[&#39;United Statesd&#39;]).reset_index() . . table5 = pd.read_excel(&#39;tab015.xlsx&#39;, index_col=0, header=3) table5 = table5.iloc[: , :-1] . . Dashboard . The collapsed code below will show how I created the Dashboard. This dashboard highlights a few key points about the doctoral data. . We show the increase in doctoral recipients over times, and how that increase has slowed in recent decades. | We show a comparison of the number of doctorate recipients in each subject category. Life Sciences still produces the most doctorate recipients. | We show how the number of male and female doctorate recipients has changed over time. | We show how the number of doctoral graduates varies by State (specifically in the Year 2017). | . import dash from dash.dependencies import Input, Output from dash import dcc from dash import html from jupyter_dash import JupyterDash import pandas as pd from datetime import datetime as dt import plotly.graph_objects as go app = JupyterDash(&#39;Hello World&#39;) def stock_prices(): fig = go.Figure([go.Bar(x = t402[&#39;State or location&#39;], y = t402[&#39;United Statesd&#39;]) ]) fig.update_layout(title = &#39;Doctorate Recipients by Subject Category&#39;, xaxis_title = &#39;Subject&#39;, yaxis_title = &#39;Number of Doctorate Recipients&#39; ) fig.update_layout(xaxis_tickangle=-45) return fig def other_graph(): fig = go.Figure([go.Scatter(x = table5.columns, y = table5.loc[&#39;Female&#39;], name = &#39;Female&#39;) ]) fig.add_trace(go.Scatter(x = table5.columns, y = table5.loc[&#39;Male&#39;], name = &#39;Male&#39;)) fig.update_layout(title = &#39;Doctorate Recipients By Sex Over Time&#39;, xaxis_title = &#39;Year&#39;, yaxis_title = &#39;Number of Doctorate Recipients&#39; ) return fig def make_map(): fig = go.Figure(data=go.Choropleth( locations=t401[&#39;abbrev&#39;], # Spatial coordinates z = t401[&#39;Totala&#39;].astype(float), # Data to be color-coded locationmode = &#39;USA-states&#39;, # set of locations match entries in `locations` colorscale = &#39;Reds&#39;, text=t401[&#39;Text&#39;], colorbar_title = &quot;Number of Doctoral Graduates&quot;, )) fig.update_layout( title_text = &#39;Doctoral Graduates By State &amp; Subject Area (2017)&#39;, geo_scope=&#39;usa&#39;, # limite map scope to USA ) return fig app.layout = html.Div([ html.Div([ dcc.Dropdown( id=&#39;my-dropdown&#39;, options=[ {&#39;label&#39;: &#39;Doctorate Recipients Over Time&#39;, &#39;value&#39;: &#39;Doctorate recipients&#39;}, {&#39;label&#39;: &#39;Percent Change in Doctorate Recipients Over Time&#39;, &#39;value&#39;: &#39;% change from previous year&#39;} ], value=&#39;Doctorate recipients&#39; ), dcc.Graph(id=&#39;my-graph&#39;) ], style={&#39;width&#39;: &#39;49%&#39;, &#39;display&#39;: &#39;inline-block&#39;}), html.Div([ dcc.Graph(id = &#39;line_plot&#39;, figure = stock_prices()) ], style={&#39;width&#39;: &#39;49%&#39;, &#39;display&#39;: &#39;inline-block&#39;}), html.Div([ dcc.Graph(id = &#39;other_line_plot&#39;, figure = other_graph()) ], style={&#39;display&#39;: &#39;block&#39;}), html.Div([ dcc.Graph(id = &#39;map&#39;, figure = make_map()) ], style={&#39;display&#39;: &#39;block&#39;}) ]) @app.callback(Output(&#39;my-graph&#39;, &#39;figure&#39;), [Input(&#39;my-dropdown&#39;, &#39;value&#39;)]) def update_graph(selected_dropdown_value): df = table2 return { &#39;data&#39;: [{ &#39;x&#39;: df.Year, &#39;y&#39;: df[str(selected_dropdown_value)] }], &#39;layout&#39;: {&#39;margin&#39;: {&#39;l&#39;: 40, &#39;r&#39;: 0, &#39;t&#39;: 20, &#39;b&#39;: 30}} } . . app.run_server(mode=&#39;inline&#39;) .",
            "url": "https://jgy4.github.io/fp.github/2021/10/21/Is-There-Life-After-Graduate-School.html",
            "relUrl": "/2021/10/21/Is-There-Life-After-Graduate-School.html",
            "date": " • Oct 21, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Creating Effective Visualizations",
            "content": "The Task . In this blog post we will explore and understand malaria with three informative visualizations. The malaria data came from this github: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-11-13. . Plotly . I chose to use plotly for my visualizations because it was easily integrated into Jupyter notebook. Plotly allows you to easily create interactive visualizations using python. I found it to be straightforward and easily customizable. . import plotly.io as pio pio.renderers.default=&#39;notebook_connected&#39; # Inject the missing require.js dependency. from IPython.display import display, HTML js = &#39;&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js&quot; integrity=&quot;sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&#39; display(HTML(js)) . . Load Data . import pandas as pd import plotly.express as px from IPython.display import HTML import pandas as pd import plotly import plotly.express as px from IPython.display import display_html, HTML from io import StringIO . . df_inc = pd.read_csv(&#39;malaria_inc.csv&#39;) df_deaths = pd.read_csv(&#39;malaria_deaths.csv&#39;) df_deaths_age = pd.read_csv(&#39;malaria_deaths_age.csv&#39;) #Make df for values within income vars income_set = [&#39;Early-demographic dividend&#39;,&#39;Low &amp; middle income&#39;,&#39;Low income&#39;,&#39;Lower middle income&#39;,&#39;Middle income&#39;,&#39;Upper Middle Income&#39;] df_inc_only = df_inc[df_inc[&#39;Entity&#39;].isin(income_set)] . . Malaria Cases By Country . This first visualization shows how many cases of malaria are occurring per 1,000 people in countries around the world from 2000 - 2015. We see that the countries with the most cases of malaria are concentrated in Africa, South America, and Southeast Asia. Especially in Africa, almost all countries are experiencing 12 cases per 1,000 population. We also notice that some countries have reduced their case numbers from 2000 to 2015. . fig1 = px.choropleth(df_inc, locations=&#39;Code&#39;, color=&#39;Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)&#39;, color_continuous_scale=&quot;blues&quot;, range_color=(0, 12), scope=&quot;world&quot;, labels={&#39;Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)&#39;:&#39;Cases per 1,000&#39;}, title=&quot;Malaria Cases By Country&quot;, animation_frame=&quot;Year&quot; ) fig1.update_geos(projection_type=&quot;natural earth&quot;) #HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #fig.update_layout(margin={&quot;r&quot;:0,&quot;t&quot;:0,&quot;l&quot;:0,&quot;b&quot;:0}) fig1.show() #HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #HTML(fig.to_html()) . . . Malaria Deaths by Country . In this second visualization we look at how many malaria deaths are occuring in each country. The metric changes to deaths per 100,000 people. We see that most malaria deaths are concentrated in the African continent and some small parts of Southeast Asia. Many African countries are experiencing 12 deaths per 100,000 people. . fig2 = px.choropleth(df_deaths, locations=&#39;Code&#39;, color=&#39;Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)&#39;, color_continuous_scale=&quot;blues&quot;, range_color=(0, 12), scope=&quot;world&quot;, labels={&#39;Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)&#39;:&#39;Deaths per 100,000&#39;}, title=&quot;Malaria Deaths By Country&quot; ) #fig.update_layout(margin={&quot;r&quot;:0,&quot;t&quot;:0,&quot;l&quot;:0,&quot;b&quot;:0}) fig2.update_geos(projection_type=&quot;natural earth&quot;) fig2.show() #HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #HTML(fig2.to_html()) . . . Malaria Deaths in Africa 1990-2016 . In this third visualization we look at malaria deaths in African countries from 1990 - 2016. Because the malaria cases and deaths were both concentrated in African countries, this visualizations explores African countries across individual years. We see that malaria deaths worsened in the late 90&#39;s and early 2000&#39;s for the continent. . fig3 = px.choropleth(df_deaths, locations=&#39;Code&#39;, color=&#39;Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)&#39;, color_continuous_scale=&quot;blues&quot;, range_color=(0, 12), scope=&quot;africa&quot;,animation_frame=&quot;Year&quot;, labels={&#39;Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)&#39;:&#39;Deaths per 100,000&#39;}, title=&quot;Malaria Deaths in Africa 1990-2016&quot; ) #fig.update_layout(margin={&quot;r&quot;:0,&quot;t&quot;:0,&quot;l&quot;:0,&quot;b&quot;:0}) fig3[&quot;layout&quot;].pop(&quot;updatemenus&quot;) # optional, drop animation buttons fig3.show() #HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #HTML(fig.to_html()) . . .",
            "url": "https://jgy4.github.io/fp.github/2021/09/30/Creating-Effective-Visualizations-Final.html",
            "relUrl": "/2021/09/30/Creating-Effective-Visualizations-Final.html",
            "date": " • Sep 30, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Number Theory",
            "content": "In the blog post below, I will outline my solution to a twist on a Google recruitment question. In solving the problem, I rely on smaller helper functions. I also implement unit testing for each helper function and my overall function. . The Problem . We are asked to find the first 10-digit prime in the decimal expansion of 17$ pi$. . The first 5 digits in the decimal expansion of $ pi$ are 14159. The first 4-digit prime in the decimal expansion of $ pi$ are 4159. We are asked to find the first 10-digit prime in the decimal expansion of 17$ pi$. . To accomplish this we use three helper functions to: . Generate a large decimal expansion of any number | Check if a number is prime | Generate sliding windows of a specified width from a long iterable | Generating a Large Decimal Expansion . In this first helper function we want to generate a large decimal expansion of any given number. To do this, we use the mpmath library. The function, called &quot;num_times&quot;, takes in the number we wish to expand, the number of digits we desire for the expansion, and a multiplier called &quot;times&quot;. The function notes the number of desired digits, and then return the decimal expansion of that number, multiplied by the multiplier. . Below the function we have a unit test. The test shows that our function can correctly expand pi to 3.14159. The second part of the test shows that it can multiply and create much larger expansions with the 100-digit expansion of $17 pi$. . from mpmath import * &quot;&quot;&quot; Write a function generate a large decimal expansion of any number (like pi) &quot;&quot;&quot; def num_times(num, digits, times): &quot;&quot;&quot; set number of digits using input &quot;&quot;&quot; mp.dps = digits &quot;&quot;&quot; multiply the number by the desired constant from input &quot;&quot;&quot; return(str(times*num)) . &quot;&quot;&quot; Unit Test &quot;&quot;&quot; &quot;&quot;&quot; 6 digit expansion of pi should be 3.14159 &quot;&quot;&quot; print(num_times(mp.pi,6,1)) &quot;&quot;&quot; 100 digit expansion of 17 pi should be 53.___ &quot;&quot;&quot; print(num_times(mp.pi,100,17)) . 3.14159 53.40707511102648505386493751575154903135187978937679895657405806923287890686555297667659203081599016 . Checking if a Number is Prime . In this second helper function we want to take a given number and return whether or not it is prime. To do this, we begin with the factor 2. While x, our number of interest, is greater than or equal to the square of our factor we want to check of x in divisible by our factor. If x is divisible by the factor, then we return False. If x isn&#39;t divisible by the factor, then we increase the factor by 1 and go through the while loop again. Once x is not greater than the square of our factor, we know we have explored all possible factors, and we can declare the number a prime number. . Below the function we have a unit test. The test shows that our function correctly identify prime numbers. Our function identifies 5 as prime, 8 as not prime, and 17 as prime. . &quot;&quot;&quot; Write a function to check if a number is prime &quot;&quot;&quot; def is_prime_num(x): p = 2 &quot;&quot;&quot; Check if x is greater than or equal to the square of p &quot;&quot;&quot; while (p*p &lt;= x): &quot;&quot;&quot; Check if x is divisible by the factor, p &quot;&quot;&quot; if (x%p == 0): &quot;&quot;&quot; If x is divisible, it is not prime - return False &quot;&quot;&quot; return False else: p+=1 &quot;&quot;&quot; Once we&#39;ve checked all possible factors - return True &quot;&quot;&quot; return True . &quot;&quot;&quot; Unit test &quot;&quot;&quot; &quot;&quot;&quot; Is 5 a prime number? True &quot;&quot;&quot; print(is_prime_num(5)) &quot;&quot;&quot; Is 8 a prime number ? False &quot;&quot;&quot; print(is_prime_num(8)) &quot;&quot;&quot; Is 17 a prime number? True &quot;&quot;&quot; print(is_prime_num(17)) . True False True . Generating Sliding Windows of a Specified Width . In this third helper function we want to take in a long string and return a list of sliding windows. We want the sliding windows to be of the specified length, n. We begin by creating an empty list called windows, and cleaning the input string of any decimal points. Then, we loop through each character in the string except for the last n, to avoid going past the end of the string. We add a window of length n to our list, windows. Once the loop ends, we return windows. . Below the function we have a unit test. The test shows our function can return sliding windows of size 5 for &#39;abcdefghijklmnop&#39; and sliding windows of size 7 for the decimal &#39;5.467892346&#39;. . &quot;&quot;&quot; Write a function to generate sliding windows of a specified width from a long iterable &quot;&quot;&quot; def slide_n(n,long_str): windows = [] &quot;&quot;&quot; Clean string of decimal points &quot;&quot;&quot; long_str = long_str.replace(&#39;.&#39;, &#39;&#39;) &quot;&quot;&quot; Loop through each character, until n before the end of the string &quot;&quot;&quot; for i in range(0,len(long_str)-(n-1)): &quot;&quot;&quot; Add sliding window of size n to windows &quot;&quot;&quot; temp_str = long_str[i:i+n] windows.append(temp_str) &quot;&quot;&quot; Return windows &quot;&quot;&quot; return windows . &quot;&quot;&quot; Unit Test &quot;&quot;&quot; &quot;&quot;&quot; Can we create sliding ranges of 5 letters for the first part of alphabet? &quot;&quot;&quot; print(slide_n(5,&#39;abcdefghijklmnop&#39;)) &quot;&quot;&quot; Can we create sliding ranges of 5 numbers for a decimal? &quot;&quot;&quot; print(slide_n(7,&#39;5.467892346&#39;)) . [&#39;abcde&#39;, &#39;bcdef&#39;, &#39;cdefg&#39;, &#39;defgh&#39;, &#39;efghi&#39;, &#39;fghij&#39;, &#39;ghijk&#39;, &#39;hijkl&#39;, &#39;ijklm&#39;, &#39;jklmn&#39;, &#39;klmno&#39;, &#39;lmnop&#39;] [&#39;5467892&#39;, &#39;4678923&#39;, &#39;6789234&#39;, &#39;7892346&#39;] . Find The First n-digit Prime in The Decimal Expansion of a Number . In our final function we use all of our helper functions to solve our question of interest - finding the first 10-digit prime number in the decimal expansion of $17 pi$. Our function can find the first n-digit prime in the decimal expansion of a number. The function takes as input: the number (ex. $ pi$), any multipliers for the number (ex. 17), the desired window length (ex. 10), and the desired decimal expansion length (ex. 1000). The function first calls num_time to generate the full decimal expansion of the desired number. Then, we feed the window length and full decimal expansion to slide_n to generate our list of sliding windows. Finally, we loop through our sliding windows, checking if each is prime, and return the first prime number we find. If we don&#39;t find any primes after looping through all windows, we return a string encouraging the user to try a longer decimal expansion. . Below our function we have unit test, seeking the first ten digit prime in the decimal expansion of e (7427466391). We begin by testing a decimal expansion of 100, but find we need a longer decimal expansion. With a decimal expansion of 1000 we see our function returns the correct answer. . Fianlly, we are able to answer our initial question below our unit test. The first 10-digit prime in the decimal expansion of $17 pi$ is &#39;8649375157&#39;. . &quot;&quot;&quot; Find the first n-digit prime in the decimal expansion of a number. &quot;&quot;&quot; def first_n_prime(num,multiplier,window,dec_length): &quot;&quot;&quot; Get the full decimal expansion of the number &quot;&quot;&quot; full_str = num_times(num,dec_length,multiplier) &quot;&quot;&quot; Create the sliding windows of size n &quot;&quot;&quot; windows = slide_n(window,full_str) &quot;&quot;&quot; Loop through all windows &quot;&quot;&quot; for i in range(0,len(windows)): &quot;&quot;&quot; Check if each window is prime, and return the first prime found &quot;&quot;&quot; if (is_prime_num(int(windows[i]))): return windows[i] else: continue &quot;&quot;&quot; If no primes were found, return a message to the user &quot;&quot;&quot; return str(&quot;Try a longer decimal expansion.&quot;) . &quot;&quot;&quot; Unit Test &quot;&quot;&quot; &quot;&quot;&quot; Search for first ten digit prime of e - with only 100 decimals we do not find it &quot;&quot;&quot; y = first_n_prime(mp.e,1,10,100) &quot;&quot;&quot; First ten digit prime of e should be 7427466391, we find it with 1000 decimals &quot;&quot;&quot; z = first_n_prime(mp.e,1,10,1000) print(z) . 7427466391 . &quot;&quot;&quot; Answer our original question: First 10-digit prime in the decimal expansion of 17 pi &quot;&quot;&quot; first_n_prime(mp.pi,17,10,1000) . &#39;8649375157&#39; . &quot;&quot;&quot; Check that it is prime &quot;&quot;&quot; is_prime_num(8649375157) . True .",
            "url": "https://jgy4.github.io/fp.github/2021/09/16/Number-Theory.html",
            "relUrl": "/2021/09/16/Number-Theory.html",
            "date": " • Sep 16, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Math Is Fun - Solving Problems From The Euler Project",
            "content": "In the blog below I will outline my solutions to three problems from The Euler project. The first, being the easiest, has been solved by less than 500,000 people. The second has been solved by less than 100,000 people. The third has been solved by less than 25,000 people. The problems are numbered as they appear on The Euler Project site https://projecteuler.net/archives. . Problem 6 - Sum Square Difference . Solved By 496,296 . https://projecteuler.net/problem=6 . We are asked to find the difference between the &quot;sum of the squares&quot; of the first one hundred natural numbers and the &quot;square of the sum&quot; of the first one hundred natural numbers. . For example, the &quot;sum of the squares&quot; of the first ten natural numbers is: $$1^2 + 2^2 + ... + 10^2 = 385$$ . The &quot;square of the sum&quot; of the first 10 natural numbers is: $$(1+2+...+10)^2 = 55^2 = 3025$$ . The function I used to obtain my solution is below. I forst compute the sum of squares. I begin by looping through the specified amount of natural numbers, in this case 100, and totaling the square of each number. Then, I compute the square of the sum by looping through the 100 natural numbers. I add them all together and square the total. Lastly, the function returns the difference by subtracting the two. Our answer is 25,164,150. . def sum_square_diff(num): &quot;&quot;&quot; Compute the sum of the squares Begin with sum_s equaling zero, and add each natural number squared. &quot;&quot;&quot; sum_s = 0 for i in range(1,num+1): sum_s += i**2 &quot;&quot;&quot; Compute the square of the sum Begin with sum_s equaling zero, and add each natural number. Square the sum at the end. &quot;&quot;&quot; s_sum = 0 for j in range(1,num+1): s_sum += j s_sum = s_sum**2 &quot;&quot;&quot; Return the difference by subtracting &quot;&quot;&quot; return(s_sum - sum_s) . &quot;&quot;&quot; Our answer for the first 100 natural numbers is shown below. &quot;&quot;&quot; sum_square_diff(100) . 25164150 . Problem 27 - Quadratic Primes . Solved by 88,173 . https://projecteuler.net/problem=27 . Considering quadratics of the form: $$n^2+an+b, |a|&lt;1000, |b| leq1000$$ We are asked to find the product of the coefficients, $a$ and $b$, for the quadratic expression that produces the maximum number of primes for consecutive values of $n$, starting with $n=0$. . For example, there is a formula: $$n^2 - 79n +1601$$ Which produces 80 primes for the consecutive values $0 leq n leq 79$. The product of the coefficients, -79 and 1601, is -126,479. . My code solution is shown below. I begin by creating a helper function that checks if a number is a prime. The main function, called quad_primes, loops through all possible values of a and b. For each possible value of a and b, the function checks if the result is a prime number. If the result is a prime number, then a while loop continues to increment n until the result is no longer prime. The function records the max count of prime numbers and the a and b values associated with that max count. The coefficients with the maximum number of primes for consecutive values of n are $a=-61$ and $b=971$. The product of these two coefficients is -59,231. . &quot;&quot;&quot; Check if a number is prime. &quot;&quot;&quot; def check_prime(num): &quot;&quot;&quot; Prime numbers must be &gt; 1. &quot;&quot;&quot; if (num &gt; 1): for i in range(2,num): &quot;&quot;&quot; If number is divisible by anything, it&#39;s not prime. &quot;&quot;&quot; if (num % i) == 0: return False return True else: return False . def quad_primes(a_max,b_max): &quot;&quot;&quot; Begin with a, b, and count values at zero. &quot;&quot;&quot; prime_num = 1 best_a = 0 best_b = 0 max_count = 0 &quot;&quot;&quot; Loop through all possible values of a and b. &quot;&quot;&quot; for a in range(-999,a_max+1): for b in range(-1000,b_max+1): n = 0 count = 0 prime_num = b &quot;&quot;&quot; For the set (a,b) - track the count of consecutive primes. &quot;&quot;&quot; while(check_prime(prime_num)): count += 1 n += 1 prime_num = n**2 + (a*n) + b &quot;&quot;&quot; Check if count is higher than all other counts, and save values. &quot;&quot;&quot; if(count &gt; max_count): best_a = a best_b = b max_count = count return([max_count,best_a,best_b,best_a * best_b]) . var = quad_primes(999,1000) . print(&#39;The max count of prime numbers is {}&#39;.format(var[0])) print(&#39;The value of a is {}.&#39;.format(var[1])) print(&#39;The value of b is {}.&#39;.format(var[2])) print(&#39;The product of a and b is {}&#39;.format(var[3])) . . The max count of prime numbers is 71 The value of a is -61. The value of b is 971. The product of a and b is -59231 . Problem 85 - Counting Rectangles . Solved by 24,609 . https://projecteuler.net/problem=85 . Although there exists no rectangular grid that contains exactly two million rectangles, find the area of the grid with the nearest solution. . For example, a 3x2 grid contains 18 rectangles. . The brute force solution is pretty easy to derive. If the grid is X long and Y high, we want to find rectangles with sides which are 1≤x≤X and 1≤y≤Y. . In case are looking for rectangles of size MxN there will be (X-M+1)*(Y-N+1) possible ways to place that rectangles. . We begin with a helper function called num_rect that counts how many rectangles are contained in an (X,Y) grid. This helper function loops through all possible rectangle shapes. For each rectangle of size HxW, the grid contains $(X-h+1)*(Y-W+1)$ of those rectangles. . The main function, called count_rect, takes the goal number of rectangles as input. Then the function loops through possible dimensions for a grid. For each grid, the total number of rectangles is calculated. We save the grid that&#39;s closest to our goal number of rectangles. The closest we could get to 2,000,000 rectangles is 1,999,998 with a 36x77 grid. . &quot;&quot;&quot; Calculate the total number of rectangles in an (X,Y) grid. &quot;&quot;&quot; def num_rect(X,Y): num_rect = 0 for h in range(1,X+1): for w in range(1,Y+1): &quot;&quot;&quot; We add to the total with each size of rectangle (h,w). &quot;&quot;&quot; num_rect += (X - h + 1)*(Y - w + 1) return num_rect . import numpy as np def count_rect(goal): best_h = 0 best_w = 0 best_diff = goal &quot;&quot;&quot; Loop through possible grid values. &quot;&quot;&quot; for i in range(0,200): for j in range(i,200): &quot;&quot;&quot; If grid is closest to goal, save values. &quot;&quot;&quot; if (np.abs(goal - num_rect(i,j)) &lt; best_diff): best_diff = np.abs(goal - num_rect(i,j)) best_h = i best_w = j return[best_h,best_w,num_rect(best_h,best_w)] . result = count_rect(2000000) print(&#39;The closest we could get to 2,000,000 rectangles is {}&#39;.format(result[2])) print(&#39;The size of the grid with {} rectangles is {}x{}.&#39;.format(result[2],result[0],result[1])) . . The closest we could get to 2,000,000 rectangles is 1999998 The size of the grid with 1999998 rectangles is 36x77. .",
            "url": "https://jgy4.github.io/fp.github/2021/09/01/Math-Is-Fun.html",
            "relUrl": "/2021/09/01/Math-Is-Fun.html",
            "date": " • Sep 1, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jgy4.github.io/fp.github/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jgy4.github.io/fp.github/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jgy4.github.io/fp.github/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}